#!/usr/bin/env python3
"""
LangChain ê¸°ë°˜ ì±„ìš©ê³µê³  ìš”ì•½ ì‹œìŠ¤í…œ - MVP
ê°œì„  ì‚¬í•­:
- CLI ì˜µì…˜ ë„ì…, í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ êµ¬ì„±(MODEL_NAME, TEMPERATURE, DISCORD_ENABLED)
- ë¡œê¹… í‘œì¤€í™”
- ìŠ¤í¬ë˜í•‘ ì¬ì‹œë„/ë°±ì˜¤í”„ + ì›ë¬¸/ì •ì œ í…ìŠ¤íŠ¸ ìºì‹œ(output/raw)
- Discord ì „ì†¡ì€ ì˜µì…˜í™”(--discord) ë° ë©”ì‹œì§€ ë¶„í• ì€ senderì—ì„œ ì²˜ë¦¬
"""

import sys
import os
import argparse
import logging
import hashlib
from datetime import datetime
from pathlib import Path
from typing import Optional, Tuple

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup

from src.chain import JobSummaryChain
from src.discord_sender import SimpleDiscordSender


LOGGER = logging.getLogger("jd_scanner")


def _slugify(value: str, max_length: int = 80) -> str:
    allowed = []
    for ch in value.lower().strip():
        if ch.isalnum():
            allowed.append(ch)
        elif ch in [" ", "-", "_"]:
            allowed.append("_")
    slug = "".join(allowed)
    while "__" in slug:
        slug = slug.replace("__", "_")
    slug = slug.strip("_")
    return slug[:max_length] or "job_posting"


def _build_requests_session() -> requests.Session:
    session = requests.Session()
    retries = Retry(
        total=4,
        backoff_factor=0.8,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET", "HEAD"],
        raise_on_status=False,
    )
    adapter = HTTPAdapter(max_retries=retries, pool_connections=10, pool_maxsize=10)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    return session


class JobPostingSummarizer:
    def __init__(self, model_name: str = "gpt-oss:20b", temperature: float = 0.1):
        """ì±„ìš©ê³µê³  ìš”ì•½ê¸° ì´ˆê¸°í™”"""
        self.chain = JobSummaryChain(model_name=model_name, temperature=temperature)
        self.session = _build_requests_session()

    def extract_content_from_url(self, url: str) -> str:
        """URLì—ì„œ ì±„ìš©ê³µê³  ë‚´ìš© ì¶”ì¶œ"""
        try:
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            }

            response = self.session.get(url, headers=headers, timeout=25)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, "html.parser")

            for script in soup(["script", "style"]):
                script.decompose()

            text = soup.get_text()
            lines = (line.strip() for line in text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            content = " ".join(chunk for chunk in chunks if chunk)

            if not content.strip():
                raise ValueError("ì¶”ì¶œëœ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

            # ì›ë¬¸/ì •ì œ í…ìŠ¤íŠ¸ ìºì‹œ ì €ì¥
            try:
                output_raw = Path("output/raw")
                output_raw.mkdir(parents=True, exist_ok=True)
                url_hash = hashlib.sha1(url.encode("utf-8")).hexdigest()[:10]
                ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                with open(output_raw / f"{url_hash}_{ts}.html", "wb") as f_html:
                    f_html.write(response.content)
                with open(output_raw / f"{url_hash}_{ts}.txt", "w", encoding="utf-8") as f_txt:
                    f_txt.write(content)
            except Exception as cache_err:
                LOGGER.debug(f"ì›ë¬¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {cache_err}")

            return content

        except requests.exceptions.RequestException as e:
            raise Exception(f"URL ìš”ì²­ ì‹¤íŒ¨: {e}")
        except Exception as e:
            raise Exception(f"ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    def summarize_job_posting(self, content: str, verbose: bool = False) -> str:
        """ì±„ìš©ê³µê³  ë‚´ìš© ìš”ì•½ (í† í° ì œí•œ ìë™ ì²˜ë¦¬)"""
        try:
            result = self.chain.run_summary(content, verbose=verbose)
            return result
        except Exception as e:
            raise Exception(f"ìš”ì•½ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    def save_summary(self, summary: str, filename: Optional[str] = None) -> str:
        """ìš”ì•½ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            t_slug, c_slug = self._extract_title_company(summary)
            mid = f"{c_slug}_{t_slug}".strip("_") or "job_posting"
            filename = f"job_posting_{mid}_{timestamp}.md"

        output_dir = Path("output")
        output_dir.mkdir(exist_ok=True)

        file_path = output_dir / filename

        try:
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(summary)
            return str(file_path)
        except Exception as e:
            raise Exception(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    def _extract_title_company(self, summary: str) -> Tuple[str, str]:
        title = ""
        company = ""
        for line in summary.splitlines():
            txt = line.strip()
            if not title and (txt.startswith("## ê³µê³ ëª…:") or txt.startswith("## ê³µê³ ëª… :")):
                title = txt.split(":", 1)[-1].strip()
            if not company and (txt.startswith("### íšŒì‚¬ëª…:") or txt.startswith("### íšŒì‚¬ëª… :")):
                company = txt.split(":", 1)[-1].strip()
            if title and company:
                break
        return _slugify(title), _slugify(company)


def _configure_logging(verbose: bool = False):
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
        datefmt="%H:%M:%S",
    )


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="JD-Scanner: ì±„ìš©ê³µê³  ìš”ì•½ê¸°")
    parser.add_argument("--url", help="ì±„ìš©ê³µê³  URL")
    parser.add_argument("--model", default=os.getenv("MODEL_NAME", "gpt-oss:20b"), help="Ollama ëª¨ë¸ëª…")
    parser.add_argument("--temperature", type=float, default=float(os.getenv("TEMPERATURE", "0.1")), help="LLM temperature")
    parser.add_argument("--discord", action="store_true", default=(os.getenv("DISCORD_ENABLED", "false").lower() == "true"), help="Discord ì „ì†¡ í™œì„±í™”")
    parser.add_argument("--verbose", action="store_true", help="ìì„¸í•œ ë¡œê·¸ ì¶œë ¥")
    args = parser.parse_args()

    _configure_logging(args.verbose)

    print("ğŸ§ª LangChain ê¸°ë°˜ ì±„ìš©ê³µê³  ìš”ì•½ ì‹œìŠ¤í…œ - MVP")
    print("=" * 50)

    url = args.url
    if not url:
        url = input("ğŸ“Œ ì±„ìš©ê³µê³  URLì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()

    if not url:
        print("âŒ URLì´ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    if not (url.startswith("http://") or url.startswith("https://")):
        print("âŒ ì˜¬ë°”ë¥¸ URL í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. (http:// ë˜ëŠ” https://ë¡œ ì‹œì‘í•´ì•¼ í•¨)")
        sys.exit(1)

    try:
        # ìš”ì•½ê¸° ì´ˆê¸°í™”
        print("ğŸ”§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        summarizer = JobPostingSummarizer(model_name=args.model, temperature=args.temperature)

        # ë‚´ìš© ì¶”ì¶œ
        print("ğŸ“„ ì±„ìš©ê³µê³  ë‚´ìš© ì¶”ì¶œ ì¤‘...")
        content = summarizer.extract_content_from_url(url)
        print(f"âœ… ë‚´ìš© ì¶”ì¶œ ì™„ë£Œ (ê¸¸ì´: {len(content)} ê¸€ì)")

        # ìš”ì•½ ìˆ˜í–‰
        print("ğŸ¤– AI ìš”ì•½ ì²˜ë¦¬ ì¤‘... (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        summary = summarizer.summarize_job_posting(content, verbose=args.verbose)
        summary = f"{summary}  \n[ì±„ìš©ê³µê³ ]({url})"

        # Discord ì „ì†¡ (ì˜µì…˜)
        if args.discord:
            sender = SimpleDiscordSender(summary)
            sender.run()
        else:
            LOGGER.info("Discord ì „ì†¡ ë¹„í™œì„±í™” ìƒíƒœì…ë‹ˆë‹¤. --discord í”Œë˜ê·¸ ë˜ëŠ” DISCORD_ENABLED=true ì„¤ì • ì‹œ ì „ì†¡í•©ë‹ˆë‹¤.")

        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 50)
        print("ğŸ“‹ ìš”ì•½ ê²°ê³¼:")
        print("=" * 50)
        print(summary)

        # íŒŒì¼ ì €ì¥
        print("\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
        saved_path = summarizer.save_summary(summary)
        print(f"âœ… ì €ì¥ ì™„ë£Œ: {saved_path}")

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
